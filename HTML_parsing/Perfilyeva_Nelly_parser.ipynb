{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html as lhtml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "from urllib import parse\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing.dummy import  Queue\n",
    "from multiprocessing import Pool\n",
    "import gzip\n",
    "import codecs\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url, n_attempts = 3, t_sleep = 0.1):\n",
    "    for i in range(n_attempts):\n",
    "        page = requests.get(url)\n",
    "        if not page.ok:\n",
    "            print(page.status_code, file=sys.stderr)\n",
    "        else:\n",
    "            return page\n",
    "    time.sleep(t_sleep)\n",
    "    print(\"Error in getting {} page\".format(url), file=sys.stderr)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pages(сount):\n",
    "    url = get_page(\"https://gg.deals/games/?sort=metascore&type=1&page={}\".format(count))\n",
    "    if url is None:\n",
    "        print('bad')\n",
    "        return None\n",
    "    tree = lhtml.fromstring(url.text)\n",
    "    for i in range(1, 13):\n",
    "        for link in tree.xpath('//*[@id=\"games-list\"]/div[1]/div[1]/div[{}]/a[1]/@href'.format(i)):\n",
    "            links.append('https://gg.deals' + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for count in range(1, 26):\n",
    "    get_all_pages(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(сount):\n",
    "    url = get_page(\"https://gg.deals/games/?sort=metascore&type=1&page={}\".format(count))\n",
    "    if url is None:\n",
    "        print('bad')\n",
    "        return None\n",
    "    temp = []\n",
    "    tree = lhtml.fromstring(url.text)\n",
    "    for i in range(1, 13):\n",
    "        for link in tree.xpath('//*[@id=\"games-list\"]/div[1]/div[1]/div[{}]/a[1]/@href'.format(i)):\n",
    "            temp.append('https://gg.deals' + link)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "links = [] #страницы\n",
    "for count in range(1, 26):\n",
    "    links.append(get_pages(count))\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(tree):\n",
    "    link = tree.xpath('//*[@id=\"page\"]/div[2]/div/ul/li[4]/a/span//text()')\n",
    "    return link[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(soup):\n",
    "    imgs = soup.find_all('img', {'class': 'image-blur'})\n",
    "    for img in imgs:\n",
    "        image = img.get('src')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_release_date(block):\n",
    "    c = block.find('div', {'class': 'game-info-details'})\\\n",
    "             .find('p', {'class': 'game-info-details-content'}).text\n",
    "#     print(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_developer(block):\n",
    "    c = block.find('div', {'class': 'game-info-details-section game-info-details-section-developer'})\\\n",
    "         .find('p', {'class': 'game-info-details-content'}).text\n",
    "#     print(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(block):\n",
    "    temp = {}\n",
    "    temp_score= block.find('div', {'class': 'game-info-details'})\\\n",
    "         .find('div', {'class': 'game-info-details-content'})\\\n",
    "         .find_all('span', {'class': 'overlay'})\n",
    "    if temp_score is not None:\n",
    "        try:\n",
    "            temp['metacritic_score'] = (int(temp_score[0].text))\n",
    "        except IndexError:\n",
    "            temp['metacritic_score'] = None\n",
    "        try:\n",
    "            temp['user_score'] = (float(temp_score[1].text))\n",
    "        except IndexError:\n",
    "            temp['user_score'] = None\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(block):\n",
    "    reviews = {}\n",
    "    try:\n",
    "        reviews = block.find('div', {'class': 'game-info-details'})\\\n",
    "             .find('div', {'class': 'game-info-details-content'})\n",
    "        rew = reviews.find('span', {'class': 'reviews-label'}).text\n",
    "        beg_ = rew.find(' (')\n",
    "        review_label = rew[:beg_]\n",
    "        end_ = rew.find(')')\n",
    "        review_count = rew[beg_ + 2:end_].replace(',', \"\")\n",
    "        review_count = int(review_count)\n",
    "        string = reviews.find('span', {'class': 'reviews-label'})['title']\n",
    "        ind = string.find('%')\n",
    "        review_positive_pctg = int(string[:ind])\n",
    "        reviews['review_label'] = review_label\n",
    "        reviews['review_positive_pctg'] = review_positive_pctg\n",
    "        reviews['review_count'] = review_count\n",
    "    except AttributeError:\n",
    "        reviews = None\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(block):\n",
    "    genres = []\n",
    "    temp = block.find('div', {'class': 'game-info-genres tags-container'})\\\n",
    "            .find_all('a' , {'class': 'badge'})\n",
    "    for x in temp:\n",
    "        genres.append(x.text)\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(block):\n",
    "    tags = []\n",
    "    try:\n",
    "        temp = block.find('div', {'id': 'game-info-tags'})\\\n",
    "                .find_all('a' , {'class': 'badge'})\n",
    "    except AttributeError:\n",
    "        return None \n",
    "    if temp is not None:\n",
    "        for x in temp:\n",
    "            tags.append(x.text)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(block):\n",
    "    features = []\n",
    "    try:\n",
    "        temp = block.find('div', {'id': 'game-info-features'})\\\n",
    "                .find_all('a' , {'class': 'badge'})\n",
    "    except AttributeError:\n",
    "        return None \n",
    "    if temp is not None:\n",
    "        for x in temp:\n",
    "            features.append(x.text)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pc_systems(soup):\n",
    "    pc_systems = []\n",
    "    try:\n",
    "        block = soup.find('div', {'class': 'game-section bg-light game-about'})\\\n",
    "                .find('ul', {'class': 'nav'})\\\n",
    "                .find_all('a', {'role': 'button'})\n",
    "    except AttributeError:\n",
    "        return None \n",
    "    if block is not None:\n",
    "        for x in block:\n",
    "            pc_systems.append(x.text)\n",
    "    return pc_systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(tree):\n",
    "    temp = []\n",
    "    for i in range(1, 4):\n",
    "        for x in tree.xpath(\"/html/body/div[1]/div[4]/div[3]/div[1]/div/div[1]/div/div[2]/div[1]/div/div[{}]/span[1]/span[3]/span[2]\".format(i)):\n",
    "            temp.append(x.text)\n",
    "    wishlist_count = temp[0]\n",
    "    alert_count = temp[1]\n",
    "    owners_count = temp[2]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dlcs(block):\n",
    "    dlcs = []\n",
    "    try:\n",
    "        temp = block.find('section', {'id': 'game-dlcs'})\\\n",
    "                .find('div', {'class': 'games-box games-box-related-list load-more-content'})\\\n",
    "                .find_all('a', {'class': 'full-link'})\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    for x in temp:\n",
    "        if 'href' in x.attrs:\n",
    "            dlcs.append('https://gg.deals' + x['href'])\n",
    "    return dlcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dlcs(block2):\n",
    "    dlcs = []\n",
    "    temp = block2.find_all('a', {'class': 'full-link'})\n",
    "    for x in temp:\n",
    "        if 'href' in x.attrs:\n",
    "            dlcs.append('https://gg.deals' + x['href'])\n",
    "    return dlcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packs(block):\n",
    "    try:\n",
    "        temp = block.find('section', {'class': 'tab-menu-section offer-section', 'id': 'game-packs'})\\\n",
    "                .find('div', {'class': 'games-box games-box-related-list load-more-content'})\\\n",
    "                .find_all('a', {'class': 'full-link'})\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    packs = []\n",
    "    for x in temp:\n",
    "        if 'href' in x.attrs:\n",
    "            packs.append('https://gg.deals' + x['href'])\n",
    "    return packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_packs(block2):\n",
    "    packs = []\n",
    "    temp = block2.find_all('a', {'class': 'full-link'})\n",
    "    for x in temp:\n",
    "        if 'href' in x.attrs:\n",
    "            packs.append('https://gg.deals' + x['href'])\n",
    "    return packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_url(tree):\n",
    "    try:\n",
    "        link = tree.xpath('//*[@id=\"game-card\"]/div[1]/div/div[1]/div/div[1]/div/a/@href')\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    if link:\n",
    "        page = requests.get(link[0])\n",
    "        return page.url\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(link, soup):\n",
    "    try:\n",
    "        chart_link = soup.find('div', {'id': 'historical-chart-container'})['data-with-keyshops-url']\n",
    "        full_chart_url = urljoin(link, chart_link)\n",
    "        headers = {'X-Requested-With':'XMLHttpRequest'}\n",
    "        web1 = requests.get(full_chart_url, headers=headers)\n",
    "        answer = json.loads(web1.text)\n",
    "        data = answer['chartData']['deals']\n",
    "        price_history = []\n",
    "        for i in range(0, len(data)):\n",
    "            price_dict = {}\n",
    "            price_dict['ts'] = data[i]['x']\n",
    "            price_dict['price'] = data[i]['y']\n",
    "            price_dict['shop'] = data[i]['shop']\n",
    "            price_history.append(price_dict)\n",
    "        return price_history\n",
    "    except TypeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(link):\n",
    "    temp = {}\n",
    "    url = None\n",
    "    try:\n",
    "        url = get_page(link)\n",
    "        tree = lhtml.fromstring(url.text)\n",
    "        soup = BeautifulSoup(url.text, 'lxml')\n",
    "    except:\n",
    "        print(\"Error in getting {} page\".format(link), file=sys.stderr)\n",
    "        return None\n",
    "    info = {}\n",
    "    info['url'] = link\n",
    "    get_value = get_name(tree)\n",
    "    if url is not None:\n",
    "        info['status'] = True\n",
    "    if get_value is not None:\n",
    "        info['name'] = get_value\n",
    "    get_value = get_image(soup)\n",
    "    if get_value is not None:\n",
    "        info['image'] = get_value\n",
    "    #right block\n",
    "    block = soup.find('div', {'class': 'game-section game-offers'})\\\n",
    "        .find('div', {'class': 'col-right'})\n",
    "    get_value = get_release_date(block)\n",
    "    if get_value is not None:\n",
    "        info['release_date'] = get_value\n",
    "    get_value = get_developer(block)\n",
    "    if get_value is not None:\n",
    "        info['developer'] = get_value\n",
    "    get_value = get_scores(block)\n",
    "    if get_value is not None:\n",
    "        try:\n",
    "            info['metacritic_score'] = get_value['metacritic_score']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            info['user_score'] = get_value['user_score']\n",
    "        except KeyError:\n",
    "            pass\n",
    "    get_value = get_reviews(block)\n",
    "    if get_value is not None:\n",
    "        info['review_label'] = get_value['review_label']\n",
    "        info['review_positive_pctg'] = get_value['review_positive_pctg']\n",
    "        info['review_count'] = get_value['review_count']\n",
    "    get_value = get_genres(block)\n",
    "    if get_value is not None:\n",
    "        info['genres'] = get_value\n",
    "    get_value = get_tags(block)\n",
    "    if get_value is not None:\n",
    "        info['tags'] = get_value\n",
    "    get_value = get_features(block)\n",
    "    if get_value is not None:\n",
    "        info['features'] = get_value\n",
    "    get_value = get_pc_systems(soup)\n",
    "    if get_value is not None:\n",
    "        info['pc_systems'] = get_value\n",
    "    get_value = get_counts(tree)\n",
    "    if get_value is not None:\n",
    "        info['wishlist_count'] = get_value[0]\n",
    "        info['alert_count'] = get_value[1]\n",
    "        info['owners_count'] = get_value[2]\n",
    "        \n",
    "        \n",
    "#     block have changed!!!    \n",
    "    block = soup.find('div', {'class': 'game-section game-offers'})\\\n",
    "            .find('div', {'class': 'col-left'})\n",
    "    get_value = get_dlcs(block)\n",
    "    if get_value is not None:    \n",
    "        info['dlcs'] = get_value\n",
    "    try:\n",
    "        block2 = soup.find('div', {'class': 'game-related-container list-more-wrapper list-more-ajax-wrapper load-more-container'})\n",
    "        get= block2.find('a', {'class': 'widget-link-more news-list-show-more-link load-more-button'})\n",
    "        response = get['data-url']\n",
    "        main_content = urljoin(link, response)\n",
    "        page2 = requests.get(main_content,headers = {'X-Requested-With':'XMLHttpRequest'})\n",
    "        soup2 = BeautifulSoup(page2.text, 'lxml')\n",
    "        get_value = get_full_dlcs(soup2)\n",
    "        if get_value is not None:    \n",
    "            info['dlcs'] += get_value\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    get_value = get_packs(block)\n",
    "    if get_value is not None:    \n",
    "        info['packs'] = get_value\n",
    "    try:\n",
    "        block2 = soup.find('section', {'class': 'tab-menu-section offer-section', 'id': 'game-packs'})\\\n",
    "                .find('div', {'class': 'game-related-container list-more-wrapper list-more-ajax-wrapper load-more-container'})\n",
    "        get= block2.find('a', {'class': 'widget-link-more news-list-show-more-link load-more-button'})\n",
    "        response = get['data-url']\n",
    "        main_content = urljoin(link, response)\n",
    "        page2 = requests.get(main_content,headers = {'X-Requested-With':'XMLHttpRequest'})\n",
    "        soup2 = BeautifulSoup(page2.text, 'lxml')\n",
    "        get_value = get_full_packs(soup2)\n",
    "        if get_value is not None:    \n",
    "            info['packs'] += get_value\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    get_value = get_market_url(tree)\n",
    "    if get_value is not None:    \n",
    "        info['market_url'] = get_value        \n",
    "    get_value = get_price_history(link, soup)\n",
    "    if get_value is not None:    \n",
    "        info['price_history'] = get_value        \n",
    "    \n",
    "    return info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queue = []\n",
    "for a in links:\n",
    "    for i in a:\n",
    "        Queue.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(Queue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be3754c85074a15a57bcc034fa654d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(Queue)) as pbar:\n",
    "    lock = pbar.get_lock()\n",
    "    with Pool(processes=15) as pool:\n",
    "        for i, info in enumerate(pool.imap(process_page, Queue)):\n",
    "            with gzip.open('data/part_{:05d}.jsonl.gz'.format(i), mode='wb') as f_json:\n",
    "                f_json = codecs.getwriter('utf8')(f_json)\n",
    "#                 print(Queue[i])\n",
    "                if info is not None:\n",
    "                    info_str = json.dumps(info, ensure_ascii=False)\n",
    "                    print(info_str, file=f_json)\n",
    "                else:\n",
    "                    print(\"error\", file=sys.stderr)\n",
    "                with lock:\n",
    "                    pbar.update(1)\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
